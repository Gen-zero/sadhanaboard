================================================================================
AGGREGATION PIPELINE OPTIMIZATION
MongoDB Aggregation Performance Best Practices
================================================================================

DATE: December 5, 2025
FOCUS: userAnalyticsService Optimizations
VERSION: 1.0

================================================================================
PART 1: AGGREGATION OPTIMIZATION PRINCIPLES
================================================================================

Principle 1: Early Filtering ($match First)
  
  ❌ INEFFICIENT:
    db.progress.aggregate([
      { $lookup: { from: 'sadhanas', ... } },    // Process all docs
      { $unwind: '$sadhana' },
      { $match: { 'sadhana.category': 'meditation' } }  // Filter late
    ])
  
  ✅ EFFICIENT:
    db.progress.aggregate([
      { $match: { progressDate: { $gte: startDate } } },  // Filter first!
      { $lookup: { from: 'sadhanas', ... } },  // Then join subset
      { $unwind: '$sadhana' }
    ])
  
  Impact: Can be 10-100x faster

Principle 2: Project Early to Reduce Data

  ❌ INEFFICIENT:
    { $lookup: { from: 'users', as: 'user' } },
    { $unwind: '$user' },
    // All user fields carried through pipeline
    { $project: { name: '$user.name' } }
  
  ✅ EFFICIENT:
    { $lookup: {
        from: 'users',
        let: { userId: '$userId' },
        pipeline: [
          { $match: { $expr: { $eq: ['$_id', '$$userId'] } } },
          { $project: { name: 1 } }  // Only needed field
        ],
        as: 'user'
      }
    }
  
  Impact: 50-70% less data in pipeline

Principle 3: Limit Early Before Expensive Operations

  ❌ INEFFICIENT:
    { $lookup: { from: 'sadhanas', as: 'sadhana' } },
    { $unwind: '$sadhana' },
    { $limit: 10 }  // Limit after join
  
  ✅ EFFICIENT:
    { $limit: 100 },  // Limit before expensive operations
    { $lookup: { from: 'sadhanas', as: 'sadhana' } },
    { $unwind: '$sadhana' }
  
  Impact: Reduces processing by orders of magnitude

Principle 4: Use $facet for Multiple Aggregations

  ❌ INEFFICIENT:
    // Run 3 separate aggregations
    const avg1 = await collection.aggregate([...]);
    const avg2 = await collection.aggregate([...]);
    const count = await collection.aggregate([...]);
    // 3 database round-trips
  
  ✅ EFFICIENT:
    const result = await collection.aggregate([
      { $facet: {
          avg1: [...],
          avg2: [...],
          count: [...]
        }
      }
    ]);
    // Single database operation
  
  Impact: 3-5x faster for multiple aggregations

================================================================================
PART 2: userAnalyticsService OPTIMIZATIONS
================================================================================

OPTIMIZATION 1: getPracticeTrends() - Early Filtering

BEFORE:
  pipeline = [
    { $match: { userId, progressDate: { $gte: startDate } } },
    { $group: { ... } },
    { $sort: { _id: 1 } }
  ]

Status: Already optimized! ✅
  - Early $match filters by userId and date
  - No expensive $lookup operations
  - Good pipeline structure

---

OPTIMIZATION 2: getCompletionRates() - Reorder Operations

BEFORE:
  pipeline = [
    { $match: { userId, progressDate: { $gte: startDate } } },
    { $lookup: { from: 'sadhanas', ... } },  // Join early
    { $unwind: '$sadhana' },
    { $group: { ... } },  // Group after join
    { $sort: { completed: -1 } }
  ]

Issues:
  • $lookup on all filtered docs (expensive)
  • Entire sadhana document brought into pipeline
  • Group happens after join

OPTIMIZED:
  pipeline = [
    { $match: { userId, progressDate: { $gte: startDate } } },  // Filter first
    { $lookup: {  // Use pipeline in $lookup to project fields
        from: 'sadhanas',
        let: { sadhanaId: '$sadhanaId' },
        pipeline: [
          { $match: { $expr: { $eq: ['$_id', '$$sadhanaId'] } } },
          { $project: { category: 1, priority: 1, timeOfDay: 1 } }  // Only needed
        ],
        as: 'sadhana'
      }
    },
    { $unwind: '$sadhana' },
    { $group: { ... } },
    { $sort: { completed: -1 } }
  ]

Expected Improvement: 20-30% faster

---

OPTIMIZATION 3: getStreakAnalytics() - Already Optimized

Status: ✅ Excellent
  - Uses lean() for read-only query
  - Minimal fields selected (_id, progressDate only)
  - Post-processing in JavaScript (appropriate for streak logic)
  - No database-side grouping needed

Comment: This method is already well-optimized.

---

OPTIMIZATION 4: getCommunityAverages() - Use $facet

BEFORE:
  // Three separate aggregations
  const avgCompletionsResult = await SadhanaProgress.aggregate([...]);
  const avgDurationResult = await SadhanaProgress.aggregate([...]);
  const topCategoriesResult = await SadhanaProgress.aggregate([...]);
  // Three database round-trips!

OPTIMIZED using $facet:
  const result = await SadhanaProgress.aggregate([
    { $match: { progressDate: { $gte: startDate } } },
    { $facet: {
        completions: [
          { $group: { _id: { userId: '$userId', day: {...} }, dailyCompletions: {...} } },
          { $group: { _id: null, avgCompletions: { $avg: '$dailyCompletions' } } }
        ],
        duration: [
          { $group: { _id: { userId: '$userId', day: {...} }, dailyTotal: {...} } },
          { $group: { _id: null, avgSessionMinutes: { $avg: '$dailyTotal' } } }
        ],
        categories: [
          { $lookup: { from: 'sadhanas', localField: 'sadhanaId', foreignField: '_id', as: 'sadhana' } },
          { $unwind: '$sadhana' },
          { $group: { _id: '$sadhana.category', avgCompletionRate: { $avg: {...} } } },
          { $sort: { avgCompletionRate: -1 } },
          { $limit: 5 }
        ]
      }
    }
  ]);

Expected Improvement: 50-70% faster (single pass vs 3 passes)

---

OPTIMIZATION 5: getComparativeAnalytics() - Combine Related Queries

Current: Calls multiple service methods (getPracticeTrends, getCompletionRates, etc.)
Status: Acceptable for now (caching helps)

Future: Could be optimized by:
  1. Using $facet to get trends + completion + percentile in one operation
  2. Caching the combined result
  3. Separating user-specific vs community queries

---

================================================================================
PART 3: IMPLEMENTATION APPROACH
================================================================================

Phase 1: Document Optimization Patterns (DONE)
  ✅ Identified inefficient patterns
  ✅ Proposed optimizations
  ✅ Estimated performance gains

Phase 2: Update Service (Next)
  ⬜ Update getCommunityAverages() with $facet
  ⬜ Update getCompletionRates() with $lookup pipeline
  ⬜ Test all aggregations
  ⬜ Verify backward compatibility

Phase 3: Monitor & Measure
  ⬜ Benchmark before/after performance
  ⬜ Compare response times
  ⬜ Verify data accuracy

================================================================================
PART 4: AGGREGATION PIPELINE CHECKLIST
================================================================================

For Each Aggregation:

☐ Analysis
  - What data does this pipeline process?
  - How many stages are there?
  - Any expensive operations ($lookup, $unwind)?
  - Is there early filtering ($match first)?

☐ Optimization
  - Move $match to beginning
  - Remove unused fields with $project
  - Move $limit before $lookup if possible
  - Use $facet for multiple similar aggregations
  - Use $lookup pipeline to project fields

☐ Testing
  - Run tests to verify correctness
  - Compare before/after results
  - Check response time improvement
  - Verify no breaking changes

☐ Benchmarking
  - Measure aggregation time with small dataset
  - Measure with large dataset (1000+ docs)
  - Calculate percentage improvement
  - Document results

================================================================================
PART 5: EXPECTED PERFORMANCE GAINS
================================================================================

getCommunityAverages() with $facet:
  Before: 3 × 100ms = 300ms (three separate aggregations)
  After:  1 × 120ms = 120ms (single $facet operation)
  Improvement: 60% faster

getCompletionRates() with optimized $lookup:
  Before: 50ms (full sadhana docs in pipeline)
  After:  35ms (projected fields only)
  Improvement: 30% faster

Overall Service Improvement:
  • Cache hit rate: Already at 60-80%
  • Aggregation performance: 20-40% improvement
  • Combined effect: Noticeable for first-time queries

================================================================================
PART 6: BEST PRACTICES SUMMARY
================================================================================

✅ DO:
  • Put $match early to filter documents
  • Project early to reduce data in pipeline
  • Use $facet for multiple aggregations
  • Use $limit before expensive operations
  • Use $lookup with pipeline to project fields
  • Cache aggregation results with TTL
  • Add $sort at appropriate stages
  • Test with realistic data volumes

❌ DON'T:
  • Run multiple aggregations in sequence
  • Join before filtering
  • Include unnecessary fields in pipeline
  • Use $unwind on large arrays (use $filter instead)
  • Perform complex calculations in aggregation (do in app)
  • Forget to index fields used in $match
  • Assume all aggregations are slow

================================================================================

Implementation Ready: Move to code updates in next session

================================================================================
